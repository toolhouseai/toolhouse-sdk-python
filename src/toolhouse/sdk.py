# This file was generated by liblab | https://liblab.com/

"""
Creates a Toolhouse class.
Generates the main SDK with all available queries as attributes.

Class:
    Toolhouse
"""
import os
from enum import Enum
from typing import List, Union, Dict, Any, Optional

from .exceptions import ToolhouseError
from .net.environment import Environment
from .services.tools import Tools
from .services.local_tools import LocalTools
from .services.llamaindex import LlamaIndex
from .models.Provider import Provider as ProviderModel
from .models.RunToolsRequest import RunToolsRequest
from .models.GetToolsRequest import GetToolsRequest
from .models.Stream import (
    ToolhouseStreamStorage,
    GroqStream,
    OpenAIStream,
    stream_to_chat_completion,
)
from warnings import warn


class Toolhouse:
    """
    A class representing the full Toolhouse SDK

    Attributes
    ----------
    tools : Tools

    Methods
    -------
    set_base_url(url: str)
        Sets the end URL
    set_api_key(api_key)
        Set the api_key
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        provider: Union[ProviderModel, str] = ProviderModel.OPENAI,
        environment: Environment = Environment.DEFAULT,
        access_token: Optional[str] = None,
    ) -> None:
        """
        Initializes the Toolhouse SDK class.

        Parameters
        ----------
        api_key : str
            The API key
        provider : ProviderModel
            The provider model or name
        environment : Environment
            The environment that the SDK is accessing
        """
        if not provider:
            raise ValueError(
                "Parameter provider is required, cannot be empty or blank."
            )
        self.provider = self._enum_matching(provider, ProviderModel.list(), "provider")
        if access_token is not None and api_key is None:
            warn(
                "access_token property will be deprecated on next major release, please use api_key instead"
            )
            api_key = access_token
        if access_token is None and api_key is None:
            api_key = os.environ.get("TOOLHOUSE_API_KEY", None)
        if api_key is None:
            raise ToolhouseError(
                "The api_key client option must be set either by passing api_key to the SDK or by setting the TOOLHOUSE_API_KEY environment variable"
            )
        self.api_key = api_key
        self.tools = Tools(api_key)
        self.metadata: Dict[str, Any] = {}
        self.set_base_url(
            environment.value if isinstance(environment, Environment) else environment
        )
        self.local_tools: LocalTools = LocalTools()
        self.llama_index: LlamaIndex = LlamaIndex(self.tools)
        self.bundle: str = "default"

    def register_local_tool(self, local_tool):
        """Register Local Tools"""
        return self.local_tools.register_local_tool(local_tool)

    def set_metadata(self, key: str, value) -> None:
        """
        Sets User Metadata

        Parameters
        ----------
            key
            value
        """
        self.metadata[key] = value

    def set_provider(self, provider: ProviderModel) -> None:
        """
        Sets User Metadata

        Parameters
        ----------
        provider : ProviderModel
            The provider model or name
        """
        self.provider = self._enum_matching(provider, ProviderModel.list(), "provider")

    def set_base_url(self, url: str) -> None:
        """
        Sets the end URL

        Parameters
        ----------
            url:
                The end URL
        """
        self.tools.set_base_url(url)

    def set_access_token(self, token: str) -> None:
        """
        Sets auth token key

        Parameters
        ----------
        token: string
            Auth token value
        """
        warn("This method will be deprecated please use set_api_key instead")
        self.tools.set_api_key(token)

    def set_api_key(self, api_key: str) -> None:
        """
        Sets api key

        Parameters
        ----------
        api_key: string
            Api key value
        """
        self.tools.set_api_key(api_key)

    def get_tools(self, bundle="default"):
        """
        Get Tools
        """
        self.bundle = bundle
        request = GetToolsRequest(
            provider=self.provider, metadata=self.metadata, bundle=bundle
        )
        tools = self.tools.get_tools(request)
        if self.provider in ("llamaindex", ProviderModel.LLAMAINDEX):
            return self.llama_index.get_tools(tools, request)
        else:
            return tools

    def run_tools(self, response, append: bool = True) -> List:
        """
        Run Tools based on the response.
        Parameters
        ----------
        response : Any
            The response from the provider
        append : bool
            Appends the LLM response to the list of messages in the return value.

        Returns
        -------
        List
            A list of messages
        """
        messages: List = []

        if self.provider in ("openai", ProviderModel.OPENAI):
            if isinstance(response, (ToolhouseStreamStorage, GroqStream, OpenAIStream)):
                response = stream_to_chat_completion(response)
                if response is None:
                    return []
            if response.choices[0].finish_reason != "tool_calls":
                return []
            response_message = response.choices[0].message
            # Strip audio and refusal if they're none to support compatibility with other models
            if (
                hasattr(response.choices[0].message, "audio")
                and response.choices[0].message.audio is None
            ):
                del response.choices[0].message.audio
            if (
                hasattr(response.choices[0].message, "refusal")
                and response.choices[0].message.refusal is None
            ):
                del response.choices[0].message.refusal

            if append:
                msg = response_message.model_dump()
                del msg["function_call"]
                messages.append(msg)
            tool_calls = getattr(response_message, "tool_calls", None)

            if tool_calls:
                for tool in tool_calls:
                    if tool.function.name in self.local_tools.get_registered_tools():
                        result = self.local_tools.run_tools(tool)
                        messages.append(result.model_dump())
                    else:
                        run_tool_request = RunToolsRequest(
                            tool, self.provider, self.metadata, self.bundle
                        )
                        run_response = self.tools.run_tools(run_tool_request)
                        messages.append(run_response.content)

        elif self.provider in ("anthropic", ProviderModel.ANTHROPIC):
            if response.stop_reason != "tool_use":
                return []

            message: dict = {"role": "user", "content": []}
            for tool in response.content:
                if tool.type == "tool_use":
                    if tool.name in self.local_tools.get_registered_tools():
                        result = self.local_tools.run_tools(tool)
                        message["content"].append(result.model_dump())
                    else:
                        run_tool_request = RunToolsRequest(
                            tool, self.provider, self.metadata, self.bundle
                        )
                        run_response = self.tools.run_tools(run_tool_request)
                        output = run_response.content
                        message["content"].append(output)
            if message["content"]:
                if append:
                    messages.append({"role": "assistant", "content": response.content})
                messages.append(message)

        else:
            raise NotImplementedError("Provider not supported")

        return messages

    @classmethod
    def _enum_matching(
        cls, value: Union[str, Enum], enum_values: List[str], variable_name: str
    ):
        str_value = value.value if isinstance(value, Enum) else value
        if str_value in enum_values:
            return value
        else:
            raise ValueError(
                f"Invalid value for {variable_name}: must match one of {enum_values}"
            )
